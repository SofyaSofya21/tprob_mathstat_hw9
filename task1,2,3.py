import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Task 1
# Даны значения величины заработной платы заемщиков банка (zp) и значения их поведенческого 
# кредитного скоринга (ks): 
# zp = [35, 45, 190, 200, 40, 70, 54, 150, 120, 110], 
# ks = [401, 574, 874, 919, 459, 739, 653, 902, 746, 832]. 
# Используя математические операции, посчитать коэффициенты линейной регрессии, 
# приняв за X заработную плату (то есть, zp - признак), а за y - значения скорингового балла 
# (то есть, ks - целевая переменная). Произвести расчет как с использованием intercept, так и без.

zp = np.array([35, 45, 190, 200, 40, 70, 54, 150, 120, 110])
ks = np.array([401, 574, 874, 919, 459, 739, 653, 902, 746, 832])
x = zp
y = ks
R2 = np.corrcoef(x,y)**2 # 0.7876 - коэф детерминации
print(R2)

b1 = (np.mean(x*y) - np.mean(x) * np.mean(y))/(np.mean(x**2) - np.mean(x)**2) # 2.62053888
b0 = np.mean(y) - b1 * np.mean(x) # 444.1773573
print(b1, b0)

n = len(x)
# с интерсептом
X = x.reshape((n,1))
Y = y.reshape(n,1)
X = np.hstack([np.ones((n,1)),X])
B = np.dot(np.linalg.inv(np.dot(X.T,X)), X.T @ Y)
print(B) # 444.17735732, 2.62053888
# y = 444.17735732 + 2.62053888 * x

# без интерсепта
X = x.reshape((n,1))
Y = y.reshape(n,1)
B = np.dot(np.linalg.inv(np.dot(X.T,X)), X.T @ Y)
print(B) # 5.88982042
# y = 5.88982042 * x


# Task 2
# Посчитать коэффициент линейной регрессии при заработной плате (zp), 
# используя градиентный спуск (без intercept).
def mse_(B1, y = y, x = x, n = len(x)):
    return np.sum(B1 * x - y)**2/n

alfa = 1e-6
b1 = 0.1
n = len(x)

for i in range(3000):
    b0 -= alfa * (2/n)*np.sum((b1*x - y))
    b1 -= alfa * (2/n)*np.sum((b1*x - y) * x)
    if i%300 == 0:
        print('iteration {}, B1 = {}, mse_ = {}'.format(i,b1,mse_(b0, b1)))
# Результат: B1 = 5.88982042013267
# кроме того, с каждой итерацией значение ошибки возрастает - это значит, что модель только хуже становится?


# Task 3
# Произвести вычисления как в пункте 2, но с вычислением intercept. 
# Учесть, что изменение коэффициентов должно производиться на каждом шаге одновременно 
# (то есть изменение одного коэффициента не должно влиять на изменение другого во время одной итерации).
def mse_(B0, B1, y = y, x = x, n = len(x)):
    return np.sum(B0 + B1 * x - y)**2/n

alfa = 5e-5
b0 = 0.1
b1 = 0.1
n = len(x)

for i in range(1000001):
    b0 -= alfa * (2/n)*np.sum((b0 + b1*x - y))
    b1 -= alfa * (2/n)*np.sum((b0 + b1*x - y) * x)
    if i%10000 == 0:
        print('iteration {}, B0 = {}, B1 = {}, mse_ = {}'.format(i,b0,b1,mse_(b0, b1)))
# Результат: b0 = 444.17735731943424, B1 = 2.6205388824390177
# Тут значение среднеквадратичной ошибки уменьшается, значит, модель улучшается с каждой итерацией